{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Papercup Data Engineer Take Home Exercise\n",
    "\n",
    "In this project, we have a SQLite database that has been filled with a realistic dataset. The test is made up of two sections.\n",
    "\n",
    "The first section focuses on data modeling and querying skills, and the 2nd section focuses on data engineering skills. You are free to use any tools to aid you with the solutions and feel free to use a search engine as you go. The entire exercise is expected to take 2 hours.\n",
    "\n",
    "## Getting started\n",
    "\n",
    "The first step is to copy this notebook into your Google Drive or Github Gist. Navigate to the \"File\" dropdown in the upper left corner and select your preferred option. This will create a copy of this notebook for you to work on.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assesment Criteria\n",
    "\n",
    "You will be assesed on:\n",
    "\n",
    "- Correctness and completeness of your answers\n",
    "- Quality of code \n",
    "- Level of detail provided in solutions\n",
    "\n",
    "## Submitting your answers\n",
    "\n",
    "Once you have completed all the tasks, share this notebook with us by providing a link to the notebook on Github Gist or your Google Drive."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "\n",
    "At Papercup our goal is to make the world's content accessible to everyone. To achieve our goal, and ensure we provide accurate and high-quality translation we have a Human in the Loop system. For each asset that is uploaded to our platform, a native speaker (**QA**) validates the transcription, translation, and the final audio output to ensure we have matched our customer expectations. All the steps a QA takes to validate an asset is referred to as a **workflow**.\n",
    "\n",
    "A workflow can consist of multiple steps, that could be reoccurring, depending on the asset and quality thresholds achieved by the QA. For example, a QA can correct transcription of the first half of the video, then translate the first half, and then switch back to the transcription again. Alternatively, after the quality control (**QC**) process, there could be number of issues raised such as translation errors or inconsistencies. Therefore, a QA would need to re-review some parts of the video.\n",
    "\n",
    "A QA may perform additional tasks involved in the process of a producing a video, such as quality control (QC), a step mentioned in an earlier example. They may require doing further research on the video or topic to ensure the accuracy of the translation, they may help engage in feature testing with the machine learning team or the product team. In the end, Papercup is billed by each QA for the total amount of time they have spent working for Papercup.\n",
    "\n",
    "Depending on a number of factors, such as duration, category and complexity of the video, a QA may spend multiple days working on a video."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 1\n",
    "\n",
    "For accurate KPI tracking and billing, we would like to have an accurate attribution model. The attribution model should let us breakdown the work done based on the asset and work type. To understand better the workflow, and cost breakdown of each asset, we propose to use a time tracking feature on our systems. The data will be used to drive the attribution model that is used for KPI tracking. At the same time, the information should be surfaced to the QA, to be verified for validity and mutated if any work was done outside the systems and presentable to Papercup as a final bill from the QA for their work.\n",
    "\n",
    "### Job Stories\n",
    "\n",
    "#### As a QA:\n",
    "\n",
    "- I would like to be able to see all videos I have worked on, and how long I spent on each video\n",
    "- I would like to be able to view the hours I worked on Papercup systems broken down by day, week, and month.\n",
    "- When I review how much time I have spent on each video, I want to be have the option to dispute the time tracked by the system\n",
    "- When I review how much time I have spent on each video, I want to be able to manually add additional tasks that cannot be captured by the timer\n",
    "- When I perform work which is not captured at video level, I want to be able to track that time, so I can be compensated for my work.`\n",
    "- Capture time spent in real-time, visible to the QA\n",
    "\n",
    "#### As a QA Manager:\n",
    "\n",
    "- I would like to be able to see a breakdown of billed hours based on video and additional tasks recorded.\n",
    "- I would like to be able to see the difference recorded by the system and reported by the QA on a video\n",
    "- I would like to be able to see the total hours billed per day/week/month per QA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1A Design a data model\n",
    "\n",
    "Propose a data model design that will facilitate all the usage cases outline in the specification above.Â  Define your assumptions, and what data storage solution you would use, provide your reasoning and how you would design the schema. You can assume a following data model already exists:\n",
    "\n",
    "    SourceVideo:\n",
    "        id: string\n",
    "        created_at: DateTime\n",
    "        last_updated_at: DataTime\n",
    "        language: string\n",
    "        category: string\n",
    "\n",
    "    TranslatedVideo:\n",
    "        id: string\n",
    "        created_at: DateTime\n",
    "        last_updated_at: DataTime\n",
    "        language: string\n",
    "        source_video_id: string\n",
    "        due_date: DateTime\n",
    "        assigned_qa: string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1B: Compute QA productivity\n",
    "\n",
    "We define QA productivity in-terms of ratio of number of minutes spent by a QA working on a minute of a video. For example, if a 5 minute video required 60 minutes of QA time, our productivity is 12 minutes per minute of a video.\n",
    "\n",
    "Based on the data model you defined, write a query or a script to compute:\n",
    "\n",
    "- For each QA their average productivity across all their videos\n",
    "- For each video, QA productivity\n",
    "- For each QA compute the difference between system reported time and disputed time by QA\n",
    "- Average QA productivity based on video properties such as category and language ordered by highest values to lowest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For our machine learning data, we pre-compute different transformations on the audio files (utterances). An utterance can come from a data set (corpus), which can be an in-house commissioned, purchased, or an open dataset. Each utterance has meta data associated with it such as style and language. \n",
    "\n",
    "To ensure the training data is consistent, we apply the following transformations on top of the audio file: trim, clip, and down sample. A transformation can use an output of a previous transformation as input. \n",
    "\n",
    "The diagram below shows the schema that models how the data is structured.\n",
    "\n",
    "![schema](./db.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can download the data with the command below"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture\n",
    "!wget https://github.com/papercup-ai/data-engineer-take-home/raw/master/papercup.db"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Denormalize the data\n",
    "\n",
    "We would like to denormalize the data into a flat structure, and write a script to create a flat data structure (CSV).  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('base': conda)",
   "name": "python373jvsc74a57bd07458f9147317f932e89359c3e76ab5a6d49df7c7a429430e8d5f6da64198267e"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3-final"
  },
  "metadata": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  },
  "orig_nbformat": 2
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
